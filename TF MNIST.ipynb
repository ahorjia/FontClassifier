{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF's logistic regression example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of arrays in this file: \n",
      " [u'fonts']\n",
      "(1000, 64, 64)\n",
      "(1000, 64, 64)\n",
      "(1000, 4096)\n",
      "(1000, 4096)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "with h5py.File('../fonts.hdf5','r') as hf:\n",
    "    print('List of arrays in this file: \\n', hf.keys())\n",
    "    data = hf.get('fonts')\n",
    "    \n",
    "    smallDataSize = 1000\n",
    "\n",
    "    As = data[:smallDataSize,0,:,:]\n",
    "    Bs = data[:smallDataSize,1,:,:]\n",
    "\n",
    "    As_reshaped = As.reshape((smallDataSize, 64*64))\n",
    "    Bs_reshaped = Bs.reshape((smallDataSize, 64*64))\n",
    "\n",
    "    print(As.shape)\n",
    "    print(Bs.shape)\n",
    "    \n",
    "    print(As_reshaped.shape)\n",
    "    print(Bs_reshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900\n",
      "100\n",
      "True\n",
      "(900, 4096)\n",
      "(900, 4096)\n",
      "(100, 4096)\n",
      "(100, 4096)\n"
     ]
    }
   ],
   "source": [
    "training_size = (int)(smallDataSize * 0.90)\n",
    "test_size = smallDataSize - training_size\n",
    "\n",
    "print(training_size)\n",
    "print(test_size)\n",
    "print(training_size + test_size == smallDataSize)\n",
    "As_reshaped_training = As_reshaped[:training_size, :]\n",
    "Bs_reshaped_training = Bs_reshaped[:training_size, :]\n",
    "\n",
    "As_reshaped_test = As_reshaped[training_size:, :]\n",
    "Bs_reshaped_test = Bs_reshaped[training_size:, :]\n",
    "\n",
    "print(As_reshaped_training.shape)\n",
    "print(Bs_reshaped_training.shape)\n",
    "print(As_reshaped_test.shape)\n",
    "print(Bs_reshaped_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([0, 1, 2, 3, 4, 5, 6, 8, 9, 12, 13, 15, 16, 17, 19, 20, 25, 26, 29, 30, 31, 33, 34, 35, 38, 40, 41, 42, 43, 46, 47, 50, 55, 60, 63, 64, 69, 71, 72, 78, 79, 82, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 100, 104, 106, 107, 108, 110, 115, 118, 119, 121, 122, 123, 124, 126, 128, 133, 138, 142, 144, 146, 148, 149, 151, 152, 154, 156, 157, 159, 162, 164, 165, 166, 168, 169, 171, 172, 174, 177, 182, 186, 192, 193, 194, 196, 198, 199, 202, 204, 205, 206, 209, 213, 214, 215, 217, 219, 220, 222, 224, 227, 228, 229, 230, 231, 232, 233, 234, 235, 237, 238, 240, 241, 242, 243, 244, 245, 246, 247, 249, 250, 251, 252, 253, 254, 255])\n"
     ]
    }
   ],
   "source": [
    "print(set(Bs_reshaped[0,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "\n",
    "# Import data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "FLAGS = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "0.9171\n"
     ]
    }
   ],
   "source": [
    "# from tensorflow.examples.tutorials.mnist import input_data\n",
    "# mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "\n",
    "# Create the model\n",
    "x = tf.placeholder(tf.float32, [None, 64 * 64])\n",
    "W = tf.Variable(tf.zeros([64 * 64, 64 * 64]))\n",
    "b = tf.Variable(tf.zeros([64 * 64]))\n",
    "y = tf.matmul(x, W) + b\n",
    "\n",
    "# Define loss and optimizer\n",
    "y_ = tf.placeholder(tf.float32, [None, 64 * 64])\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y, y_))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "# Train\n",
    "tf.initialize_all_variables().run()\n",
    "for _ in range(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "\n",
    "# Test trained model\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(sess.run(accuracy, feed_dict={x: mnist.test.images,\n",
    "                                  y_: mnist.test.labels}))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
