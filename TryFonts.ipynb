{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Sample classifier with scikit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named scipy",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d10797b61032>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0miris\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_iris\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdigits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_digits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\program files\\python27\\lib\\site-packages\\sklearn\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__check_build\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0m__check_build\u001b[0m  \u001b[1;31m# avoid flakes unused variable error\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\program files\\python27\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mexternals\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfixes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named scipy"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(digits.data.shape)\n",
    "print(digits.target.shape)\n",
    "print(digits.images.shape)\n",
    "print(digits.images[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(gamma = 0.001, C=100.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "clf.fit(digits.data[:-1], digits.target[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predict\n",
    "predVal = clf.predict(digits.data[-1:])\n",
    "print(predVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(digits.target[-1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and parse font file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from fontTools.ttLib import TTFont\n",
    "font = TTFont('corbel_font.ttf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "* http://pyopengl.sourceforge.net/pydoc/fontTools.ttLib.html\n",
    "* https://searchcode.com/codesearch/view/86910536/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(font.getGlyphNames()))\n",
    "print(font.getGlyphNames()[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "font.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(font.getGlyphID('Ccaron'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(font.getGlyphOrder())\n",
    "mp = font.getGlyphSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "font.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(mp.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aGlyph = mp['A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aGlyph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import inspect\n",
    "inspect.getmembers(aGlyph, predicate=inspect.ismethod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cmap = font['cmap']\n",
    "cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inspect.getmembers(cmap, predicate=inspect.ismethod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for table in cmap.tables:\n",
    "    print(table.platformID)\n",
    "    print(table.platEncID)\n",
    "    print(table.language)\n",
    "#     print(table.cmap)\n",
    "    print(\"======================\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tabl1 = cmap.tables[0]\n",
    "# inspect.getmembers(tabl1)\n",
    "print(tabl1.cmap[65])\n",
    "\n",
    "tabl2 = cmap.tables[0]\n",
    "print(tabl2.cmap[65])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From cmap get the glyphid from character id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from fontTools.pens.ttGlyphPen import TTGlyphPen\n",
    "pen = TTGlyphPen(font.getGlyphSet())\n",
    "aGlyph.draw(pen)\n",
    "print(aGlyph._glyph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division, absolute_import\n",
    "from fontTools.misc.py23 import *\n",
    "\n",
    "import sympy as sp\n",
    "import math\n",
    "from fontTools.pens.basePen import BasePen\n",
    "from fontTools.pens.transformPen import TransformPen\n",
    "from fontTools.pens.perimeterPen import PerimeterPen\n",
    "from fontTools.pens.areaPen import AreaPen\n",
    "from fontTools.misc.transform import Scale\n",
    "from fontTools.misc.bezierTools import splitQuadraticAtT, splitCubicAtT\n",
    "from functools import partial\n",
    "\n",
    "n = 3 # Max Bezier degree; 3 for cubic, 2 for quadratic\n",
    "\n",
    "t, x, y = sp.symbols('t x y', real=True)\n",
    "\n",
    "P = tuple(zip(*(sp.symbols('%s:%d'%(w,n+1), real=True) for w in 'xy')))\n",
    "\n",
    "# Cubic Bernstein basis functions\n",
    "BinomialCoefficient = [(1, 0)]\n",
    "for i in range(1, n+1):\n",
    "    last = BinomialCoefficient[-1]\n",
    "    this = tuple(last[j-1]+last[j] for j in range(len(last)))+(0,)\n",
    "    BinomialCoefficient.append(this)\n",
    "BinomialCoefficient = tuple(tuple(item[:-1]) for item in BinomialCoefficient)\n",
    "\n",
    "BernsteinPolynomial = tuple(\n",
    "    tuple(c * t**i * (1-t)**(n-i) for i,c in enumerate(coeffs))\n",
    "    for n,coeffs in enumerate(BinomialCoefficient))\n",
    "\n",
    "BezierCurve = tuple(\n",
    "    tuple(sum(P[i][j]*bernstein for i,bernstein in enumerate(bernsteins))\n",
    "        for j in range(2))\n",
    "    for n,bernsteins in enumerate(BernsteinPolynomial))\n",
    "\n",
    "def green(f, Bezier=BezierCurve[n]):\n",
    "    f1 = -sp.integrate(sp.sympify(f), y)\n",
    "    f2 = f1.subs({x:Bezier[0], y:Bezier[1]})\n",
    "    return sp.integrate(f2 * sp.diff(Bezier[0], t), (t, 0, 1))\n",
    "\n",
    "class BezierFuncs(object):\n",
    "\n",
    "    def __init__(self, symfunc):\n",
    "        self._symfunc = symfunc\n",
    "        self._bezfuncs = {}\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        if i not in self._bezfuncs:\n",
    "            args = []\n",
    "            for d in range(i+1):\n",
    "                args.append('x%d' % d)\n",
    "                args.append('y%d' % d)\n",
    "            self._bezfuncs[i] = sp.lambdify(args, green(self._symfunc, Bezier=BezierCurve[i]))\n",
    "        return self._bezfuncs[i]\n",
    "\n",
    "_BezierFuncs = {}\n",
    "\n",
    "def getGreenBezierFuncs(func):\n",
    "    funcstr = str(func)\n",
    "    global _BezierFuncs\n",
    "    if not funcstr in _BezierFuncs:\n",
    "        _BezierFuncs[funcstr] = BezierFuncs(func)\n",
    "    return _BezierFuncs[funcstr]\n",
    "\n",
    "def printCache(func):\n",
    "    funcstr = str(func)\n",
    "    print(\"_BezierFuncs['%s'] = [\" % funcstr)\n",
    "    for i in range(n+1):\n",
    "        print('\tlambda P:', green(func, Bezier=BezierCurve[i]), ',')\n",
    "    print(']')\n",
    "\n",
    "class GreenPen(BasePen):\n",
    "\n",
    "    def __init__(self, func, glyphset=None):\n",
    "        BasePen.__init__(self, glyphset)\n",
    "        self._funcs = getGreenBezierFuncs(func)\n",
    "        self.value = 0\n",
    "\n",
    "    def _moveTo(self, p0):\n",
    "        self.__startPoint = p0\n",
    "\n",
    "    def _lineTo(self, p1):\n",
    "        p0 = self._getCurrentPoint()\n",
    "        self.value += self._funcs[1](p0[0],p0[1],p1[0],p1[1])\n",
    "\n",
    "    def _qCurveToOne(self, p1, p2):\n",
    "        p0 = self._getCurrentPoint()\n",
    "        self.value += self._funcs[2](p0[0],p0[1],p1[0],p1[1],p2[0],p2[1])\n",
    "\n",
    "    def _curveToOne(self, p1, p2, p3):\n",
    "        p0 = self._getCurrentPoint()\n",
    "        self.value += self._funcs[3](p0[0],p0[1],p1[0],p1[1],p2[0],p2[1],p3[0],p3[1])\n",
    "\n",
    "    def _closePath(self):\n",
    "        p0 = self._getCurrentPoint()\n",
    "        if p0 != self.__startPoint:\n",
    "            p1 = self.__startPoint\n",
    "            self.value += self._funcs[1](p0[0],p0[1],p1[0],p1[1])\n",
    "\n",
    "#AreaPen = partial(GreenPen, func=1)\n",
    "Moment1XPen = partial(GreenPen, func=x)\n",
    "Moment1YPen = partial(GreenPen, func=y)\n",
    "Moment2XXPen = partial(GreenPen, func=x*x)\n",
    "Moment2YYPen = partial(GreenPen, func=y*y)\n",
    "Moment2XYPen = partial(GreenPen, func=x*y)\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "# Glyph statistics object\n",
    "#\n",
    "\n",
    "class GlyphStatistics(object):\n",
    "\n",
    "    def __init__(self, glyph, transform=None, glyphset=None):\n",
    "        self._glyph = glyph\n",
    "        self._glyphset = glyphset\n",
    "        self._transform = transform\n",
    "\n",
    "    def _penAttr(self, attr):\n",
    "        internalName = '_'+attr\n",
    "        if internalName not in self.__dict__:\n",
    "            Pen = globals()[attr+'Pen']\n",
    "            pen = transformer = Pen(glyphset=self._glyphset)\n",
    "            if self._transform:\n",
    "                transformer = TransformPen(pen, self._transform)\n",
    "            self._glyph.draw(transformer)\n",
    "            self.__dict__[internalName] = pen.value\n",
    "        return self.__dict__[internalName]\n",
    "\n",
    "    Area = property(partial(_penAttr, attr='Area'))\n",
    "    Perimeter = property(partial(_penAttr, attr='Perimeter'))\n",
    "    Moment1X = property(partial(_penAttr, attr='Moment1X'))\n",
    "    Moment1Y = property(partial(_penAttr, attr='Moment1Y'))\n",
    "    Moment2XX = property(partial(_penAttr, attr='Moment2XX'))\n",
    "    Moment2YY = property(partial(_penAttr, attr='Moment2YY'))\n",
    "    Moment2XY = property(partial(_penAttr, attr='Moment2XY'))\n",
    "\n",
    "    # TODO Memoize properties below\n",
    "\n",
    "    # Center of mass\n",
    "    # https://en.wikipedia.org/wiki/Center_of_mass#A_continuous_volume\n",
    "    @property\n",
    "    def MeanX(self):\n",
    "        return self.Moment1X / self.Area\n",
    "    @property\n",
    "    def MeanY(self):\n",
    "        return self.Moment1Y / self.Area\n",
    "\n",
    "    # https://en.wikipedia.org/wiki/Second_moment_of_area\n",
    "\n",
    "    #  Var(X) = E[X^2] - E[X]^2\n",
    "    @property\n",
    "    def VarianceX(self):\n",
    "        return self.Moment2XX / self.Area - self.MeanX**2\n",
    "    @property\n",
    "    def VarianceY(self):\n",
    "        return self.Moment2YY / self.Area - self.MeanY**2\n",
    "\n",
    "    @property\n",
    "    def StdDevX(self):\n",
    "        return self.VarianceX**.5\n",
    "    @property\n",
    "    def StdDevY(self):\n",
    "        return self.VarianceY**.5\n",
    "\n",
    "    #  Covariance(X,Y) = ( E[X.Y] - E[X]E[Y] )\n",
    "    @property\n",
    "    def Covariance(self):\n",
    "        return self.Moment2XY / self.Area - self.MeanX*self.MeanY\n",
    "\n",
    "    @property\n",
    "    def _CovarianceMatrix(self):\n",
    "        cov = self.Covariance\n",
    "        return ((self.VarianceX, cov), (cov, self.VarianceY))\n",
    "\n",
    "    @property\n",
    "    def _Eigen(self):\n",
    "        mat = self.CovarianceMatrix\n",
    "        from numpy.linalg import eigh\n",
    "        vals,vecs = eigh(mat)\n",
    "        # Note: we return eigen-vectors row-major, unlike Matlab, et al\n",
    "        return tuple(vals), tuple(tuple(row) for row in vecs)\n",
    "\n",
    "    #  Correlation(X,Y) = Covariance(X,Y) / ( StdDev(X) * StdDev(Y)) )\n",
    "    # https://en.wikipedia.org/wiki/Pearson_product-moment_correlation_coefficient\n",
    "    @property\n",
    "    def Correlation(self):\n",
    "        corr = self.Covariance / (self.StdDevX * self.StdDevY)\n",
    "        if abs(corr) < 1e-3: corr = 0\n",
    "        return corr\n",
    "\n",
    "    @property\n",
    "    def Slant(self):\n",
    "        slant = self.Covariance / self.VarianceY\n",
    "        if abs(slant) < 1e-3: slant = 0\n",
    "        return slant\n",
    "\n",
    "\n",
    "def test(glyphset, upem, glyphs):\n",
    "    print('upem', upem)\n",
    "\n",
    "    for glyph_name in glyphs:\n",
    "        print()\n",
    "        print(\"glyph:\", glyph_name)\n",
    "        glyph = glyphset[glyph_name]\n",
    "        stats = GlyphStatistics(glyph, transform=Scale(1./upem), glyphset=glyphset)\n",
    "        for item in dir(stats):\n",
    "            if item[0] == '_': continue\n",
    "            print (\"%s: %g\" % (item, getattr(stats, item)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from fontTools.pens.transformPen import TransformPen\n",
    "\n",
    "glyph_name = 'A'\n",
    "glyphset = font.getGlyphSet()\n",
    "upem = font['head'].unitsPerEm\n",
    "print(\"glyph:\", glyph_name)\n",
    "glyph = font.getGlyphSet()[glyph_name]\n",
    "stats = GlyphStatistics(glyph, transform=Scale(1./upem), glyphset=glyphset)\n",
    "for item in dir(stats):\n",
    "    if item[0] == '_': continue\n",
    "    print (\"%s: %g\" % (item, getattr(stats, item)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try the HDF5 File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "smallDataSize = 10000\n",
    "\n",
    "with h5py.File('/home/agah/FontCase/fonts.hdf5','r') as hf:\n",
    "    print('List of arrays in this file: \\n', hf.keys())\n",
    "    data = hf.get('fonts')\n",
    "    print(data)\n",
    "    print(data.shape)\n",
    "    imgC = data[43611,2,:,:]\n",
    "    imgH = data[43611,7,:,:]\n",
    "    \n",
    "    As = data[:smallDataSize,0,:,:]\n",
    "    Bs = data[:smallDataSize,1,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(imgC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(imgH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(As[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(Bs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(As.shape)\n",
    "print(Bs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "As_reshaped = As.reshape((smallDataSize, 64*64))\n",
    "print(As_reshaped.shape)\n",
    "\n",
    "Bs_reshaped = Bs.reshape((smallDataSize, 64*64))\n",
    "print(Bs_reshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(As_reshaped[0,:].reshape((64,64)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(Bs_reshaped[0,:].reshape((64,64)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "class VectorRegression():\n",
    "    def __init__(self):\n",
    "        self.clf = svm.SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.2, gamma='auto',\n",
    "                            kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n, m = y.shape\n",
    "        # Fit a separate regressor for each column of y\n",
    "        self.estimators_ = [sklearn.base.clone(self.clf).fit(X, y[:, i])\n",
    "                               for i in range(m)]\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Join regressors' predictions\n",
    "        res = [est.predict(X)[:, np.newaxis] for est in self.estimators_]\n",
    "        return np.hstack(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "vr = VectorRegression()\n",
    "model = vr.fit(As_reshaped, Bs_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import libsvm\n",
    "libsvm.set_verbosity_wrap(True)\n",
    "clf = svm.LinearSVR(verbose=3)\n",
    "clf.fit(As_reshaped, Bs_reshaped[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
